{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98f192-0b39-4ce0-92e3-6d15ca30fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ==========================================\n",
    "# 1. Define Product Anatomy (Ref: Section 2.1)\n",
    "# ==========================================\n",
    "\n",
    "@dataclass\n",
    "class MARC_Instrument:\n",
    "    \"\"\"\n",
    "    Defines the structural parameters of the Multi-Asset Autocallable.\n",
    "    \"\"\"\n",
    "    # Asset parameters\n",
    "    tickers: list[str]          # List of N underlying assets\n",
    "    initial_spots: np.array     # S_i(0)\n",
    "    \n",
    "    # Barrier Logic (Section 2.1.2 & 2.1.3)\n",
    "    barrier_autocall: float     # B_KO (e.g., 1.00 or 100%)\n",
    "    barrier_knock_in: float     # B_KI (e.g., 0.60 or 60%)\n",
    "    is_american_ki: bool        # True = Continuous observation, False = European\n",
    "    \n",
    "    # Coupon Logic (Section 2.1.4)\n",
    "    coupon_rate: float\n",
    "    barrier_coupon: float       # Level to trigger coupon payment\n",
    "    with_memory: bool           # Phoenix/Memory feature toggle\n",
    "    \n",
    "    # Dates\n",
    "    observation_dates: np.array # Array of discrete observation times {t_1...t_M}\n",
    "    maturity: float             # T\n",
    "\n",
    "# ==========================================\n",
    "# 2. The Correlation Engine (Ref: Section 2.2.1)\n",
    "# ==========================================\n",
    "\n",
    "class CorrelationEngine:\n",
    "    \"\"\"\n",
    "    Handles the mathematical stability of the correlation matrix.\n",
    "    Critically, this fixes 'broken' matrices from dirty market data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raw_correlation_matrix):\n",
    "        self.raw_matrix = raw_correlation_matrix\n",
    "        self.N = raw_correlation_matrix.shape[0]\n",
    "\n",
    "    def get_stable_cholesky(self):\n",
    "        \"\"\"\n",
    "        Returns the Lower Triangular Matrix L such that L * L.T = Sigma.\n",
    "        Includes error handling for non-PSD matrices.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Attempt standard Cholesky first\n",
    "            return np.linalg.cholesky(self.raw_matrix)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # TRIGGER: Section 2.2.1 \"Technical Constraint - Positive Semi-Definiteness\"\n",
    "            # If raw Cholesky fails, the matrix is not PSD.\n",
    "            # We must project it to the nearest valid matrix.\n",
    "            print(\"WARNING: Non-PSD Matrix detected. Applying Spectral Correction...\")\n",
    "            clean_matrix = self._spectral_projection(self.raw_matrix)\n",
    "            return np.linalg.cholesky(clean_matrix)\n",
    "\n",
    "    def _spectral_projection(self, matrix):\n",
    "        \"\"\"\n",
    "        Reconstructs the matrix using only positive eigenvalues.\n",
    "        This is a simplified version of Higham's Algorithm.\n",
    "        \"\"\"\n",
    "        # 1. Eigen Decomposition\n",
    "        eigenvals, eigenvecs = np.linalg.eigh(matrix)\n",
    "        \n",
    "        # 2. Floor negative eigenvalues to a small epsilon (or 0)\n",
    "        eigenvals = np.maximum(eigenvals, 1e-8)\n",
    "        \n",
    "        # 3. Reconstruct Matrix\n",
    "        # Sigma_new = V * Lambda_clipped * V^T\n",
    "        T = 1 / (eigenvals**0.5)\n",
    "        # (Mathematical reconstruction logic omitted for brevity, \n",
    "        # but ensures the diagonal remains 1.0)\n",
    "        \n",
    "        reconstructed = (eigenvecs * eigenvals) @ eigenvecs.T\n",
    "        \n",
    "        # 4. Enforce Correlation property: Diagonal must be exactly 1.0\n",
    "        # Normalize to ensure unit diagonal\n",
    "        d = np.sqrt(np.diag(reconstructed))\n",
    "        reconstructed = reconstructed / np.outer(d, d)\n",
    "        \n",
    "        return reconstructed\n",
    "\n",
    "# ==========================================\n",
    "# Execution Example\n",
    "# ==========================================\n",
    "\n",
    "# 1. Setup the Instrument\n",
    "marc_note = MARC_Instrument(\n",
    "    tickers=[\"SPX\", \"SX5E\", \"NKY\"],\n",
    "    initial_spots=np.array([4200.0, 4100.0, 32000.0]),\n",
    "    barrier_autocall=1.0,\n",
    "    barrier_knock_in=0.6,\n",
    "    is_american_ki=True,       # Requires Brownian Bridge in step 4\n",
    "    coupon_rate=0.08,\n",
    "    barrier_coupon=0.7,\n",
    "    with_memory=True,\n",
    "    observation_dates=np.array([1.0, 2.0, 3.0]),\n",
    "    maturity=3.0\n",
    ")\n",
    "\n",
    "# 2. Prepare the Math Kernel \n",
    "# Assume we have a slightly \"broken\" correlation matrix from data\n",
    "dirty_corr = np.array([\n",
    "    [1.0, 0.9, 0.9],\n",
    "    [0.9, 1.0, 0.9],\n",
    "    [0.9, 0.9, 1.0] \n",
    "]) \n",
    "# (Note: Valid correlations sometimes fail Cholesky due to floating point noise)\n",
    "\n",
    "engine = CorrelationEngine(dirty_corr)\n",
    "L_matrix = engine.get_stable_cholesky()\n",
    "\n",
    "print(\"Initialization Complete. Cholesky Factor L is ready for Monte Carlo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
